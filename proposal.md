# Proposal

April 18th, 2022

1. My project will be an implementation of Markov chains, the seeds of which were described in Markov's 1913 lecture, "An Example of Statistical Investigation of the Text Eugene Onegin Concerning the Connection of Samples in Chains"). Markov's original contribution was simply to count the vowels and consonants in a Russian poem and thereby show that letters did not occur independently, but that each character had an effect on the next. This idea has been expanded into a number of uses, including predicting the weather, gambling, and generating text.

2. As Brian Hayes explains in [First Links in the Markov Chain](https://www.americanscientist.org/article/first-links-in-the-markov-chain), Markov's work has its basis in a growing interest in probability theory within mathematics research in the 18th and 19th centuries. Markov was inspired to work on probability theory with respect to dependent variables when his rival, Pavel Nekrasov, claimed that the law of large numbers only applied to independent variables (events like flipping a coin). After disproving Nekrasov's claim, Markov went on to apply his finding in his 1913 lecture. The "chains" in his paper refer to the states in a string of letters and the transitions between them. Markov showed that the probability distribution of letters was based on the letters that preceded them, and not simply independent. Today's applications of Markov chains are somewhat hindered by the question of how long convergence will take, which brings to mind the halting problem that Turing grappled with and eventually proved intractable in 1936.

3. I plan to write a basic Markov chain implementation with one or both of the following use cases (as time allows):

    - The first use case will be to write a Markov chain that can take (and pass) the midterm and final exams for this class. It will work by reading in all (or some) of the texts from this class and constructing an in-memory Markov chain (i.e., one chain per text). I plan to make the Markov chain parameters configurable by the user (e.g., n-grams can consist of letters or words, and n itself will be configurable). Once the chain has been constructed, the program will accept a short passage from one of the source texts and construct a Markov chain using the same parameters as before. Then, the program will choose the correct source text based on the similarity of the Markov chains. This will basically amount to comparing two two-dimensional arrays (matrices) of probabilities. If I have time, I'll run a Monte Carlo simulation where I run the program many times with different inputs and see which parameters work best. The goal of this use case will be to produce the most successful test taker. (Of course, if we wanted to produce the best test taker without using Markov chains, it would be trivial: we would search for a matching substring.)

    - The second use case will be to allow a user to blend two or more authors together to see what a hybrid text would look like. For example, a user could select Aristotle and Masterman to get a short passage on semantics and mimesis (hopefully!). It will work by constructing a single Markov chain from texts by the selected authors, and then using n-grams to construct a short passage. As before, I intend to make the parameters configurable, and the seed word of the resulting passage will be chosen at random from the Markov chain, for variability.

4. For the first use case, I hope that my program will have a better-than-random passing rate. For example, if there are ten possible sources, I hope it chooses the correct one more than 10% of the time. For the second use case, my goal is that the generated passages are somewhat believable and contain mostly real words (which is not a guarantee if I use n-grams of letters). I also hope that generating a passage based on only one author produces a somewhat believable result. Overall, I'm looking to demonstrate the surprising applicability of Markov chains in a textual context, which feels very appropriate because that's where Markov's lecture began.
